# Reconocimiento de Lenguaje de SeÃ±as Americano con IA

Un sistema de reconocimiento de lenguaje de seÃ±as americano con interfaz grÃ¡fica que utiliza detecciÃ³n de manos en tiempo real y redes neuronales convolucionales para identificar las letras.

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un sistema de reconocimiento de lenguaje de seÃ±as americano con:

- Modelo de deep learning (CNN) que alcanza mÃ¡s del 98% de precisiÃ³n
- Interfaz grÃ¡fica con detecciÃ³n de manos en tiempo real usando MediaPipe
- Procesamiento inteligente de la regiÃ³n de la mano para mejor precisiÃ³n
- VisualizaciÃ³n en tiempo real de las predicciones

El sistema estÃ¡ diseÃ±ado para reconocer las 25 letras estÃ¡ticas del alfabeto de seÃ±as americano (excluye J y Z que requieren movimiento).

## ğŸš€ InstalaciÃ³n

### Requisitos previos

- Python 3.7 o superior
- Webcam

### Dependencias

Instala todas las dependencias ejecutando:

```bash
pip install -r requirements.txt
```

Principales dependencias:
- TensorFlow
- OpenCV
- MediaPipe
- NumPy
- Pandas
- Matplotlib
- Scikit-learn
- Tkinter (incluido con Python generalmente)

## ğŸ’» Uso

### Ejecutar la interfaz grÃ¡fica

La manera mÃ¡s fÃ¡cil de usar el sistema es mediante el script de ejecuciÃ³n que automÃ¡ticamente encuentra el mejor modelo disponible:

```bash
python ejecutar_interfaz.py
```

### Entrenar un nuevo modelo

Si deseas entrenar el modelo desde cero con las mejoras implementadas:

```bash
python modelo_lenguaje_senhas_mejorado.py
```

Esto entrenarÃ¡ una red neuronal convolucional utilizando los datos de entrenamiento y guardarÃ¡ el modelo optimizado.

### Uso manual de la interfaz

TambiÃ©n puedes ejecutar directamente la interfaz:

```bash
python deteccion_senhas_gui.py
```

Y luego seguir estos pasos:
1. Haz clic en "Cargar Modelo Mejorado" (o selecciona uno manualmente)
2. Haz clic en "Iniciar Captura"
3. Muestra tu mano frente a la cÃ¡mara
4. La letra predicha aparecerÃ¡ en la parte derecha de la interfaz

## ğŸ§  Arquitectura del Modelo

El modelo implementa una red neuronal convolucional (CNN) con:

- Data augmentation integrado (rotaciÃ³n, zoom, traslaciÃ³n)
- 3 bloques convolucionales con BatchNormalization
- RegularizaciÃ³n L2 y Dropout creciente para evitar sobreajuste
- Capas densas reducidas para mejorar generalizaciÃ³n

### Mejoras especÃ­ficas:

- Dropout progresivo (0.3 â†’ 0.6)
- RegularizaciÃ³n L2 para pesos
- Tasa de aprendizaje adaptativa
- Checkpoints que guardan los mejores modelos

## ğŸ“Š Conjunto de datos

El modelo estÃ¡ entrenado con el conjunto de datos Sign MNIST, que incluye imÃ¡genes de 28x28 pÃ­xeles en escala de grises de letras del lenguaje de seÃ±as americano.

## ğŸ”§ Estructura del proyecto

```
â”œâ”€â”€ modelo_lenguaje_senhas_mejorado.py   # Script para entrenar el modelo mejorado
â”œâ”€â”€ deteccion_senhas_gui.py              # Interfaz grÃ¡fica con detecciÃ³n de manos
â”œâ”€â”€ ejecutar_interfaz.py                 # Script para ejecutar la interfaz fÃ¡cilmente
â”œâ”€â”€ prediccion_senhas.py                 # Script para realizar predicciones
â”œâ”€â”€ requirements.txt                     # Dependencias del proyecto
â”œâ”€â”€ .gitignore                           # Archivos a ignorar en el control de versiones
â”œâ”€â”€ rendimiento_modelo.png               # GrÃ¡fico de rendimiento del modelo
â”œâ”€â”€ modelo_lenguaje_senhas.h5            # Modelo original guardado
â”œâ”€â”€ modelo_lenguaje_senhas_mejorado.h5   # Modelo mejorado guardado
â”œâ”€â”€ sign_mnist_train.csv                 # Datos de entrenamiento
â”œâ”€â”€ sign_mnist_test.csv                  # Datos de prueba
â”œâ”€â”€ checkpoints/                         # Directorio donde se guardan los modelos durante entrenamiento
â””â”€â”€ logs/                                # Registros de entrenamiento para TensorBoard
```

## ğŸ” CaracterÃ­sticas de la interfaz

- **DetecciÃ³n de manos en tiempo real**: Utiliza MediaPipe para detectar y rastrear manos
- **Aislamiento automÃ¡tico**: Extrae solo la regiÃ³n de la mano para anÃ¡lisis
- **VisualizaciÃ³n de confianza**: Muestra el nivel de confianza de cada predicciÃ³n
- **Historial de predicciones**: Mantiene registro de las letras detectadas
- **Ajuste de umbral**: Permite configurar el umbral de confianza mÃ­nimo
- **VisualizaciÃ³n de landmarks**: OpciÃ³n para mostrar puntos de referencia de la mano
- **Guardado de capturas**: Permite guardar capturas de la cÃ¡mara

## ğŸ¤ Contribuir

Las contribuciones son bienvenidas. Para contribuir:

1. Haz un fork del proyecto
2. Crea una rama para tu funcionalidad (`git checkout -b feature/nueva-funcionalidad`)
3. Haz commit de tus cambios (`git commit -am 'AÃ±ade nueva funcionalidad'`)
4. Haz push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo LICENSE para mÃ¡s detalles.

## ğŸ™ Agradecimientos

- MediaPipe por la librerÃ­a de detecciÃ³n de manos
- Sign MNIST por el conjunto de datos de entrenamiento
- La comunidad de lenguaje de seÃ±as por inspirar este trabajo

## ğŸ“¬ Contacto

Si tienes preguntas o comentarios, por favor abre un issue en este repositorio. 